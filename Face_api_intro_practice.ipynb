{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a CognitiveServices credentials object with key and endpoint to create FaceClient Object\n",
    "# Creating an authenticated FaceClient\n",
    "\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect faces in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4087f38a-1f7d-454e-b230-c3a2c7f113cd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detect a face in a image that contains a single face\n",
    "single_face_image_url = 'https://www.biography.com/.image/t_share/MTQ1MzAyNzYzOTgxNTE0NTEz/john-f-kennedy---mini-biography.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "\n",
    "# we use detection model 2 beacuse we are not retriving attributes\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detectionModel='detection_02')\n",
    "\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "    \n",
    "# Display the detected face ID in the first single-face image.\n",
    "# Face ID's are used for comparision to faces (their IDs) detected in other images\n",
    "\n",
    "for face in detected_faces: print(face.face_id)\n",
    "print()\n",
    "\n",
    "#saving this id for use in Find Similar\n",
    "first_image_face_ID = detected_faces[0].face_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No face detected from image road-1072823__340.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ef06089c92ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdetected_faces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No face detected from image {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_image_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: No face detected from image road-1072823__340.jpg"
     ]
    }
   ],
   "source": [
    "# Lets try with the image which has no face\n",
    "no_face_image_url = 'https://cdn.pixabay.com/photo/2015/12/01/20/28/road-1072823__340.jpg'\n",
    "no_image_name = os.path.basename(no_face_image_url)\n",
    "\n",
    "detected_faces = face_client.face.detect_with_url(url=no_face_image_url, detectionModel='detection_02')\n",
    "\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(no_image_name))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and Frame Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing rectangle aroung face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "single_face_image_url = 'https://raw.githubusercontent.com/Microsoft/Cognitive-Face-Windows/master/Data/detection1.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detectionModel='detection_02')\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "    \n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left,top),(right,bottom))\n",
    "\n",
    "# Download the image from the url\n",
    "response = requests.get(single_face_image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box\n",
    "print('Drawing rectangle aroung face... see popup for results.')\n",
    "draw = ImageDraw.Draw(img)\n",
    "for face in detected_faces:\n",
    "    draw.rectangle(getRectangle(face), outline='red')\n",
    "    \n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code in detect faces in a image to save a reference to single face\n",
    "# the following code to get references to several faces in a group image\n",
    "# Detect the faces in a image that contains multiple faces; each detected face gets assigned a new ID\n",
    "\n",
    "multi_face_image_url = 'http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg'\n",
    "multi_image_name = os.path.basename(multi_face_image_url)\n",
    "detected_faces2 = face_client.face.detect_with_url(url=multi_face_image_url,detectionModel='detection_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the instances of first face in the group\n",
    "# create list of the face IDs found in the second image\n",
    "second_image_face_IDs = list(map(lambda x:x.face_id, detected_faces2))\n",
    "# finding similar face IDs to first Id\n",
    "similar_faces = face_client.face.find_similar(face_id=first_image_face_ID, face_ids=second_image_face_IDs)\n",
    "if not similar_faces[0]:\n",
    "    print('No similar faces found in',multi_image_name,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar faces found in president-family-portrait-closeup.jpg:\n",
      " Face ID:  5b3870e6-0d9e-4b65-a804-58684d51813e\n",
      " Face rectangle:\n",
      " Left:  413\n",
      " Top:  57\n",
      " Width:  55\n",
      " Height:  55\n"
     ]
    }
   ],
   "source": [
    "## Print Matches\n",
    "print('Similar faces found in', multi_image_name + ':')\n",
    "for face in similar_faces:\n",
    "    first_image_face_ID = face.face_id\n",
    "    face_info = next(x for x in detected_faces2 if x.face_id==first_image_face_ID)\n",
    "    if face_info:\n",
    "        print(' Face ID: ',first_image_face_ID)\n",
    "        print(' Face rectangle:')\n",
    "        print(' Left: ', str(face_info.face_rectangle.left))\n",
    "        print(' Top: ', str(face_info.face_rectangle.top))\n",
    "        print(' Width: ',str(face_info.face_rectangle.width))\n",
    "        print(' Height: ',str(face_info.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train Person group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Person Group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: e6fcc27f-7910-4fe5-857c-b6ccbbf0cf44\n"
     ]
    }
   ],
   "source": [
    "##creating person group and three person objects\n",
    "\n",
    "# Create empty person group\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Define women friend\n",
    "women = face_client.person_group_person.create(PERSON_GROUP_ID, 'Woman')\n",
    "# Define Man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, \"Man\")\n",
    "# Define child Friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID,'child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign faces to persons\n",
    "\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith('w')]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith('m')]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith('ch')]\n",
    "\n",
    "# Add to women person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, women.person_id, w)\n",
    "    \n",
    "# Add to man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "    \n",
    "# ADD to child person\n",
    "for image in child_images:\n",
    "    ch = open(image,'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Person group\n",
      "Training status: succeeded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train person group\n",
    "\n",
    "print()\n",
    "print('Training Person group')\n",
    "#Training the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print('Training status: {}'.format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify a Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to identify a image among a set of images\n",
    "\n",
    "# getting a test image\n",
    "test_image_array = glob.glob('test-image-person-group.jpg')\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "# print(\"Pausing for 60 seconds to avoid triggering rate limit on free account...\")\n",
    "# time.sleep(60)\n",
    "\n",
    "# Detect faces\n",
    "face_ids =[]\n",
    "faces = face_client.face.detect_with_stream(image, detectionModel='detection_02')\n",
    "for face in faces:\n",
    "    face_ids.append(face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify faces in test-image-person-group.jpg\n",
      "Person for face ID 8261b695-3b4f-4842-9eef-48e54a5f755e is identified in test-image-person-group.jpg with a confidence of 0.92387.\n",
      "Person for face ID 2d8ae1d8-3834-4e33-9549-a76c7dc72f41 is identified in test-image-person-group.jpg with a confidence of 0.93316.\n"
     ]
    }
   ],
   "source": [
    "# Identify faces\n",
    "# takes array of detected faces and compares to the person group\n",
    "\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identify faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "    if len(person.candidates) >0:\n",
    "        print('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence))\n",
    "    else:\n",
    "        print('No person identified for face ID {} in {}.'.format(person.face_id, os.path.basename(image.name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verifies face_ids with other face_id or person object and determines if they belong to same person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Getting Test Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_BASE_URL = 'https://csdx.blob.core.windows.net/resources/Face/Images/'\n",
    "\n",
    "# create a list to hold the target photos of the same person\n",
    "target_image_file_names = ['Family1-Dad1.jpg', 'Family1-Dad2.jpg']\n",
    "# The source photos contain this person\n",
    "source_image_file_name1 = 'Family1-Dad3.jpg'\n",
    "source_image_file_name2 = 'Family1-Son1.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detect faces for verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 face(s) detected from image Family1-Dad3.jpg.\n",
      "1 faces(s) detected from image Family1-Son1.jpg.\n",
      "1 face(s) detected from image Family1-Dad1.jpg.\n",
      "1 face(s) detected from image Family1-Dad2.jpg.\n"
     ]
    }
   ],
   "source": [
    "# Detect faces from source image 1, returns list[DetectedFaces]\n",
    "detected_faces1 = face_client.face.detect_with_url(IMAGE_BASE_URL + source_image_file_name1, detectionModel = 'detection_02')\n",
    "#Add the returned face's face id\n",
    "source_image1_id = detected_faces1[0].face_id\n",
    "print('{} face(s) detected from image {}.'.format(len(detected_faces1), source_image_file_name1))\n",
    "\n",
    "# Detect faces from source image 2, returns list[DetectedFaces]\n",
    "detected_faces2 = face_client.face.detect_with_url(IMAGE_BASE_URL + source_image_file_name2, detcetionModel='detection_02')\n",
    "source_image2_id = detected_faces2[0].face_id\n",
    "print('{} faces(s) detected from image {}.'.format(len(detected_faces2),source_image_file_name2))\n",
    "\n",
    "# List for the target face IDs (uuids)\n",
    "detected_faces_ids=[]\n",
    "# Detect faces from the target image url list, returns a list[Detect#edFaces]\n",
    "for image_file_name in target_image_file_names:\n",
    "    detected_faces = face_client.face.detect_with_url(IMAGE_BASE_URL + image_file_name, detectionModel ='detection_02')\n",
    "    detected_faces_ids.append(detected_faces[0].face_id)\n",
    "    print('{} face(s) detected from image {}.'.format(len(detected_faces), image_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get verification Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces from Family1-Dad3.jpg & Family1-Dad1.jpg are of the same person, with confidence: 0.88193\n",
      "Faces from Family1-Son1.jpg & Family1-Dad1.jpg are of a different person, with confidence: 0.26628\n"
     ]
    }
   ],
   "source": [
    "# comparing each source image to the target image and print a messae if they belong to same person\n",
    "# Since target faces are the same person, in this example, we can use the 1st ID in the detected_faces_ids list to compare.\n",
    "verify_result_same = face_client.face.verify_face_to_face(source_image1_id, detected_faces_ids[0])\n",
    "print('Faces from {} & {} are of the same person, with confidence: {}'\n",
    "    .format(source_image_file_name1, target_image_file_names[0], verify_result_same.confidence)\n",
    "    if verify_result_same.is_identical\n",
    "    else 'Faces from {} & {} are of a different person, with confidence: {}'\n",
    "        .format(source_image_file_name1, target_image_file_names[0], verify_result_same.confidence))\n",
    "\n",
    "# Verification example for faces of different persons\n",
    "verify_result_diff = face_client.face.verify_face_to_face(source_image2_id, detected_faces_ids[0])\n",
    "print('Faces from {} & {} are of the same person, with confidence: {}'\n",
    "    .format(source_image_file_name2, target_image_file_names[0], verify_result_diff.confidence)\n",
    "    if verify_result_diff.is_identical\n",
    "    else 'Faces from {} & {} are of a different person, with confidence: {}'\n",
    "        .format(source_image_file_name2, target_image_file_names[0], verify_result_diff.confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the main Person Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted the person group e6fcc27f-7910-4fe5-857c-b6ccbbf0cf44 from the source location.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "print(\"Deleted the person group {} from the source location.\".format(PERSON_GROUP_ID))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
